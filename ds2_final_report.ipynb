{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c962599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pyearth import Earth\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, cross_validate\n",
    "from patsy import dmatrix\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score, roc_curve, auc, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.ensemble import BaggingRegressor,BaggingClassifier,RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "#Libraries for visualizing trees\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image\n",
    "\n",
    "#import pydotplus\n",
    "import time as tm\n",
    "\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f49b",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d1119",
   "metadata": {},
   "source": [
    "As a student, I aimed to gain practical experience by working on a dataset that had real-world applications and relevance. Credit score prediction is a vital task for financial institutions, and having a model that accurately predicts individual credit scores can contribute to informed lending decisions and risk assessment. In addition, I wanted a dataset I knew was large enough to explore and test different modeling techniques. By utilizing bagged MARS, decision tree, random forest, and XGBoost models within my ensemble approach, I aimed to leverage the unique strengths and capabilities of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff1421",
   "metadata": {},
   "source": [
    "## Problem statement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c21daf",
   "metadata": {},
   "source": [
    "Credit scores are a crucial factor in determining an individualâ€™s financial health, and lenders heavily rely on them to assess creditworthiness and risk. However, credit score calculations can be complex and multifaceted, taking into account a range of factors such as payment history, outstanding debts, credit utilization, and length of credit history. **The goal is to build a reliable ensemble model using bagged MARS, decision tree, random forest, and XGboost models that can accurately predict individual credit scores based on multiple credit and customer-related predictors using RMSE as the evaluation metric.** This model will provide lenders with a tool to make more informed decisions and help secure better financial outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7b95f",
   "metadata": {},
   "source": [
    "## Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7258bc",
   "metadata": {},
   "source": [
    "The data source is an open source dataset found on Kaggle. The data provides 100,000 observations, 18 continuous predictors as well as four categorical predictors that will be useful in my prediction of individual credit scores. The response is a column based off `Credit_Score` called `Credit_Rating`: the way this column is prepared is discussed in the \"Data quality check / cleaning / preparation\" section of this report.  Some of the predictors include `Credit_History_Age`, `new credit`, `Credit_Mix`, `Credit_Utilization_Ratio`, and `Num_of_Delayed_Payment`, amongst many others in need of assessment. The data set can be found [here](https://www.kaggle.com/datasets/parisrohan/credit-score-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Data Quality Check / Cleaning / Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da5d5d",
   "metadata": {},
   "source": [
    "The first step taken in the data preparation was creating the new response column, `Credit_Rating`. The credit scores in the dataset are classified into \"Poor\", \"Standard\", and \"Good\". Each of the three categories were assigned random credit ratings to those with Poor credit scores (ratings from 0-579), those with Standard (ratings from 580-668), and Good (ratings from 670-729) in order to pursue a continuous response and model with regression. These credit ratings were determined using FICO score ratings found on [Investopedia](https://www.investopedia.com/terms/f/ficoscore.asp). Once the response was created, a new training dataset was created to use for the rest of the analysis.\n",
    "\n",
    "This dataset was very dirty. There were hundreds of instances where observations were surrounded by underscores and spaces that made it difficult to begin creating models. These invalid characters were removed from the columns, in addition to setting all numerical columns to the integer datatype. There were thousands of columns that were identified as outliers and errors, in addition to missing values. Before removing NAN values and outliers, the RMSE of the base model was found to be 209.98; however, upon removing these outliers and missing values, the RMSE dropped drastically to 86.83.\n",
    "\n",
    "Finally, dummy columns were made for the two categorical predictors `Credit_Mix` and `Payment_of_Min_Amount` using pd.get_dummies, and the dataset was split using test_size = 0.2 and random_state = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a8cc35e",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAGDCAYAAADK03I6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABJBUlEQVR4nO3deZxddX3/8ddn9n0mySyZTPaQPZAQQwDBBZQKVEVbF6goohVRsD/tJra21dbfr3azSrWgtVaxClhFRYoiyuKCQEJYsu/bZNbMvq+f3x/3TLyOk5mbZO6cu7yfj8d95N5zzveczzn3Tj7n+z3f8z3m7oiIiEh6yAg7ABEREZk5SvwiIiJpRIlfREQkjSjxi4iIpBElfhERkTSixC8iIpJGlPglVGZ2t5n91TSta6GZdZtZZvD5CTP7w+lYd7C+H5rZTdO1vjPY7qfM7KSZNcS4/CfM7L/jHZecGzNzMzsveD9tfwfnGNMrzGxv2HFIfCnxS9yY2REz6zOzLjNrN7OnzOxWMzv1u3P3W93972Jc12snW8bdj7l7kbuPTEPsv5U83f0ad//aua77DONYAPwJsMbd504w/9VmVjuTMaUqM/Nxn19nZj8Lfr/NZvakmb0xHtuO/js4k+80+J0OBSe8Y39jl8a63eiTjyCOn7v7yjPfgwnX/VUze/d0rEumlxK/xNsb3L0YWAR8Gvgo8J/TvREzy5rudSaIRUCLuzeFHQjAWGtKqjOztwD/A9wDzAeqgL8G3nCa5cP8/d3v7kVAOfA4kbhFTkuJX2aEu3e4+4PA24GbzGwdnKoVfCp4X25mDwU1l1Yz+7mZZZjZ14GFwA+Cms2fm9nioLbyXjM7BjwWNS36P+FlZvasmXWY2ffNbHawrd+qVY21KpjZ1cBfAG8PtvdiMP/UpYMgro+b2VEzazKze8ysNJg3FsdNZnYsaKb/y9MdGzMrDco3B+v7eLD+1wKPAvOCOL46rlwh8MOo+d1mNi+YnROss8vMdprZpqhy88zsO8H2DpvZH00S21fN7C4ze9jMeoArJitvZpvNbKuZdZpZo5l9ZtwxucXM6sys3sz+JKpcrpl9NphXF7zPjf6uzOxPgmNdb2Y3R5W91sx2Bft6wsz+NGre683shaja8AWn29eoMgZ8Bvg7d/9y8Nsddfcn3f19wTLvNrNfmtm/mlkr8IlgH/45+M4bLdJ8nx+13j8LYq8zs/dMcJw/NcV3Oil3Hwa+AdSYWUXU9/GrYP/rzezzZpYTzPtZUPTFYDtvH/93EfxN/KmZvWSRv6H7zSwvav6fR+3TH9q4FgRJUO6ul15xeQFHgNdOMP0Y8IHg/VeBTwXv/x64G8gOXq8AbKJ1AYsBJ1IjKwTyo6ZlBcs8AZwA1gXLfAf472Deq4Ha08ULfGJs2aj5TwB/GLx/D3AAWAoUAQ8AXx8X238Eca0HBoDVpzlO9wDfB4qDsvuA954uznFlJ9qPTwD9wLVAZnBcnw7mZQDPEam95gTxHwJed5r1fxXoAC4LyhZMVh74FfDO4H0RcMm4Y3Jv8F2cDzRHHe+/BZ4GKoEK4CkiiXdsH4eDZbKD/eoFZgXz64FXBO9nARuD9xuBJuDi4DjcFHzHuVP8blcFsS6ZZJl3BzF9CMgKvufPAg8Cs4Pv8gfA3wfLXw008uvf4jeDbZw3wd/BpN/5BN/12G86h0ir2kl+/TfwMuCSIMbFwG7gw1HlT8Uw0baD4/UsMC/Yr93ArVH71ACsDX4XXx+/Pr0S86Uav4Shjsh/IuMNAdXAIncf8sj1xqkeJvEJd+9x977TzP+6u+9w9x7gr4C32fQ0V78D+Iy7H3L3buBjwPX2m60Nn3T3Pnd/EXiRyAnAbwhieTvwMXfvcvcjwL8A7zzH+H7h7g97pL/D16O2fRFQ4e5/6+6D7n6IyAnK9ZOs6/vu/kt3HyWSsCcrPwScZ2bl7t7t7k+PW9cng+9rO/BfwA3B9HcAf+vuTe7eDHyS3zwGQ8H8IXd/GOgGVkbNW2NmJe7e5u7bgunvA77o7s+4+4hH+mcMEEmEk5kT/Fs/xXJ17v5vHqlp9wfb+4i7t7p7F/D/oo7L24D/ivotfmKKdZ+Jt5lZO9AXxPCWICbc/Tl3f9rdh4Pf1heBV53h+u909zp3byVyMrNhbLtE9mmnu/cS+c4kCSjxSxhqgNYJpv8TkVr0j83skJndEcO6jp/B/KNEaozlMUU5uXnB+qLXnUXkWvCY6F74vURqwOOVE6mpjV9XzTnGN37becFJySIizcjtYy8ilzWqJljHmOhjOFX59wIrgD1mtsXMXj/Juo4SOY4w8fGMbuJuGUtmUfs0djx/n0grwFGLdMAb69y2CPiTcbEuGLfeibQE/1ZPsVz0vlQQtIZEbetHwfSx/Ru/79PlW+5eRuQ72EGklg+Ama2wyOWzBjPrJHIycqa//9P9jsfv01R/i5IglPhlRpnZRUSS2i/GzwtqvH/i7kuJdKL6YzN7zdjs06xyqhaBBVHvFxKpHZ4Eeoj8Rz0WVya//k86lvXWEUks0eseJtKceyZOBjGNX9eJGMuf6eM1jwOH3b0s6lXs7tfGuI1Jy7v7fne/gUiT/T8A3w6uW48Z/33UBe8nOp51xMDdt7j7dcE2vwd8KyrW/zsu1gJ3v3eKVe4Nyv7+VJuOen+SSI17bdS2Sj3S6Q4irQfj9z2W9cbM3U8C7yfS32DspOUuYA+w3N1LiJyk2dmsfwL1RDo+jllwugUlsSjxy4wws5Kg9ncfkWuS2ydY5vVmdl7QuaoTGAleEEmoS89i0zea2RozKyByjfjbQfP3PiK14N81s2zg40BuVLlGYLFF3Xo4zr3AR8xsiZkVEalJ3T+uVjqlIJZvAf/XzIrNbBHwx0Cs9+E3AnMs6FgYg2eBTjP7qJnlm1mmma0LTsjOubyZ3WhmFcFlgfagTPTtlX9lZgVmtha4Gbg/mH4v8HEzqzCzciJ9CKY8BmaWY2bvMLNSdx/i178biFyCuNXMLraIwuD7Lp5sncHlpT8OYr05+O1mmNnlZval05QZDbb3r2ZWGcRWY2avCxb5FvDuqN/i30wSwpl+p9Fx7AEeAf48mFRM5Jh0m9kq4AMTbOts/q4gsk83m9nqYJ/++izXIzNMiV/i7Qdm1kWkBvWXRHpL33yaZZcDPyFy/fZXwL+7+xPBvL8nkhjaLarXdgy+TqTjVAOQB/wRRO4yAD4IfJlI7boHiO7lP3ZLVIuZbeO3fSVY98+Aw0Su8X7oDOKK9qFg+4eItIR8M1j/lIL/6O8FDgXHZtJm7OBE4w1ErtMeJlJT/TIQU5KJofzVwE4z6wY+B1zv7v1Rq3iSyOWcnwL/7O4/DqZ/CtgKvARsB7YF02LxTuBI0JR9K3BjEOtWIte8Pw+0Bdt9d4z7+W0ifS/eQ6TloTGI5/uTFPtosI2ng1h+QtAPwd1/SKTz32PBMo9Nsu0z+k4n8E/ALcEJyJ8CfwB0ETkxuX/csp8AvhZs521nspFgn+4kcgvhASJ/sxDpRyEJbKzHtIhI3JjZYiInCtln2ioiycHMVhPpY5Cr7zixqcYvIiJnxczeHFxumUWkT8cPlPQTnxK/iEgCs8gzIroneP1F2LER6UzYDBwk0rdifB8CSUBq6hcREUkjqvGLiIikESV+ERGRNJKqTzT7DeXl5b548eKwwxAREZkRzz333El3r5hoXlok/sWLF7N169awwxAREZkRZnbaYaHV1C8iIpJGlPhFRETSiBK/iIhIGlHiFxERSSNK/CIiImlEiV9ERCSNKPGLiIikESV+ERGRNKLELyIikkaU+EVERNKIEr+IiEgaUeIXERFJI2nxkB4RkVTQ1T/EvsYu9jd209Q1QHvvEFmZRnFuFksqCtm8eDaVJXlhhykJTolfRCRB9QwMs+VIK7861MLTB1vYfqKDUf/1/MKcTEbc6R8aPTXtwoVl3PqqZVy1uoqMDAshakl0SvwiIgmif2iEbUfbeOpgC7861MKLx9sZHnWyM40NC8q4/YrzuGB+GSuqiplbmkdOVuRq7cDwCLvru3j6UAvfeOYo7//6c1y4sIwv/MFG5pXlh7xXkmjM3adeKslt2rTJt27dGnYYIiKn9A+NsKehi+0nOth5ooMddR3sbehiaMTJMLhgfhmXLpvDpUvnsGnxLApyYqunDY+M8t3nT/DJH+wiO9P4/B9s5LLzyuO8N5JozOw5d9804TwlfhGR+OodHGZ3fSfbazvYUdfJjhMd7G/qZiRoty8ryGbdvFLW1ZSyecksLlo8m+K87HPa5qHmbm797+c42tLLN993CS9bNGs6dkWShBK/Er+IzCB3Z9uxdh7Z2cDTh1rYEXVtvrwoh3U1pUGiL2FdTSk1ZfmYTf/1+JbuAX7/rqfo6BvigQ9expLywmnfhiSm0BK/mV0NfA7IBL7s7p8eN9+C+dcCvcC73X3bZGXN7H5gZbCKMqDd3TdMFocSv4jMhKGRUe7bcpwv//wQR1t6ycnMYMPCMi5eMpsL5pdxfk0pVSW5cUnyp3PkZA+/d9dTzCnM4aE/upzcrMwZ27aEZ7LEH7fOfWaWCXwBuAqoBbaY2YPuvitqsWuA5cHrYuAu4OLJyrr726O28S9AR7z2QUQkVs8cauGj33mJIy29vGzRLD505XJet7bqnJvsz9Xi8kL+5W3rufm/tvDFJw/xR69ZHmo8Er549urfDBxw90MAZnYfcB0QnfivA+7xSLPD02ZWZmbVwOKpygatBW8DrozjPoiITMrduedXR/m7h3axYHYB/3nTJq5cVTmjtfqpXLGyktdfUM3nHz/A6y+oZmlFUdghSYjiOXJfDXA86nNtMC2WZWIp+wqg0d33T0u0IiJn4TOP7uNvHtzJq1dW8P3bL+M1q6sSKumP+es3rCE3K4O//v7OsEORkMUz8U/0yx/foeB0y8RS9gbg3tNu3OwWM9tqZlubm5snDVRE5Gw8sK2Wf3vsAG/ftIAvvXMTJSE360+msjiP//Oa5fziwEmeO9oWdjgSongm/lpgQdTn+UBdjMtMWtbMsoDfA+4/3cbd/UvuvsndN1VUVJzVDoiInM5zR9u44zvbuXTpHD715nVJMUreDZsXUlaQzd1PHgw7FAlRPBP/FmC5mS0xsxzgeuDBccs8CLzLIi4BOty9PoayrwX2uHttHOMXEZnQ0MgoH3vgJSqKc7nrxo1kZybH884Kc7O46dLFPLqrkX2NXWGHIyGJ26/V3YeB24FHgN3At9x9p5ndama3Bos9DBwCDgD/AXxwsrJRq7+eSZr5RUTi6eu/Osq+xm7+5g1rKCvICTucM/Luly8mPzuTu59QrT9daQAfEZEzcLJ7gCv++Qk2LCjjnvdsTsiOfFP5m+/v4N5nj/PsX74m6U5cJDaT3cefHO1TIiIJ4vOPHaBvcIS/ecPapEz6AG/dtIDBkVEeeqk+7FAkBEr8IiIx6h4Y5tvP1fKG9fM4rzJ574VfO6+EFVVFfPf5E2GHIiFQ4hcRidED22rpHhjmppcvDjuUc2JmvPnC+Tx3tI0jJ3vCDkdmmBK/iEgM3J2vPXWE9fNL2bCgLOxwztmbLpyHGTygWn/aUeIXEYnBUwdbONjcw7suXRx2KNOiujSfy5aV873nT5AOnbzl15T4RURicP+W48wqyOZ3L6gOO5Rpc835cznW2sv+pu6wQ5EZpMQvIjKFgeERHtvTxOvWziUvO3Uea3vlqkoAHtvTFHIkMpOU+EVEpvCrgy10DwzzO2urwg5lWlWX5rO6ukSJP80o8YuITOHHuxopzMnk5cvKww5l2r1mVSXPHW2jo3co7FBkhijxi4hMYnTUeXRXI69eWZlSzfxjrlhVycio8+R+PcU0XSjxi4hM4vnj7TR3DaRcM/+YDQvKmF2Yw2O7G8MORWaIEr+IyCR+vKuB7EzjiqAjXKrJzDBevaKCJ/c1Mzqq2/rSgRK/iMgknjrQwsaFsyjJyw47lLi57Lxy2nqH2KtH9aYFJX4RkdPo6h9iZ10HFy+dE3YocbV5yWwAnjnUEnIkMhOU+EVETmPbsXZGHS4OEmOqWjC7gJqyfJ453Bp2KDIDlPhFRE7j2cMtZGUYFy4sCzuUuLt4yWyePdyq4XvTgBK/iMhpPHu4lXU1pRTkZIUdStxdvHQ2LT2DHNDwvSlPiV9EZAL9QyO8eLwj5Zv5x1y8JNKP4Wk196c8JX4RkQm8cLydwZHRUx3fUt2iOQVUleTyrBJ/ylPiFxGZwLOHWzGDTYvSI/GbGZuXzOGZQy26zp/ilPhFRCbw3NE2VlYVU1qQuvfvj3fR4lk0dQ1wor0v7FAkjpT4RUTGcXd21nWwrqY07FBm1IYFZQC8eLwj3EAkrpT4RUTGaeoa4GT3IGvnlYQdyoxaNbeEnKwMXjjeFnYoEkdK/CIi4+ysi9R4063Gn5OVwdp5JarxpzglfhGRcXae6MQMVlenV40fYP38Mraf6GB4ZDTsUCROlPhFRMbZWdfJ4jmFFOWm/sA9421YUEbf0Aj7NZBPylLiFxEZZ2d9B2vS7Pr+mPVBB78XjreHGofEjxK/iEiUjt4hjrf2pV3HvjGL5xRQmp/Ni0r8KUuJX0Qkys76SMe2tfPSq2PfGDNj/YIy1fhTmBK/iEiUXXWdAGlb4wfYML+UfY1d9A4Ohx2KxIESv4hIlJ11nVSV5FJelBt2KKFZW1PKqMOehq6wQ5E4UOIXEYmyr7GLVXPTt7YPv27tGGv9kNSixC8iEhgddQ42d3NeZVHYoYSqpiyf0vxsdirxpyQlfhGRQF1HH/1DoyyrSO/Eb2asqS5hV70SfyqKa+I3s6vNbK+ZHTCzOyaYb2Z2ZzD/JTPbGEtZM/tQMG+nmf1jPPdBRNLHgWDQmnSv8QOsmVfCnvpOjeCXguKW+M0sE/gCcA2wBrjBzNaMW+waYHnwugW4a6qyZnYFcB1wgbuvBf45XvsgIunlYHMPAMsqCkOOJHxr55UwMDzK4ZM9YYci0yyeNf7NwAF3P+Tug8B9RBJ2tOuAezziaaDMzKqnKPsB4NPuPgDg7k1x3AcRSSMHmrqZVZDNnDTu0T9mbORCXedPPfFM/DXA8ajPtcG0WJaZrOwK4BVm9oyZPWlmF01r1CKStg42d6f99f0xyyqKyMnK0HX+FBTPxG8TTPMYl5msbBYwC7gE+DPgW2b2W8ub2S1mttXMtjY3N8cetYikrYNN6tE/Jjszg5VVxaceUSypI56JvxZYEPV5PlAX4zKTla0FHgguDzwLjALl4zfu7l9y903uvqmiouKcdkREUl9bzyAtPYOq8UdZO6+EXXWduI+vs0kyi2fi3wIsN7MlZpYDXA88OG6ZB4F3Bb37LwE63L1+irLfA64EMLMVQA5wMo77ISJp4NDJSI/+ZZXq2DdmzbwS2nqHaOjsDzsUmUZxe9i0uw+b2e3AI0Am8BV332lmtwbz7wYeBq4FDgC9wM2TlQ1W/RXgK2a2AxgEbnKdjorIOTp1K19FcciRJI4VVZFjsa+xm+rS/JCjkekSt8QP4O4PE0nu0dPujnrvwG2xlg2mDwI3Tm+kIpLuDjb3kJOVQc0sJbgxpxJ/QxevWqFLpqlCI/eJiBCp8S8tLyQzY6K+xelpdmEOFcW57G3Uw3pSiRK/iAhwpKWHJeW6vj/eyqpi9inxpxQlfhFJeyOjTm1rHwvnFIQdSsJZUVXM/sZuRkfVlSpVKPGLSNpr7OxncGSUhbOV+MdbUVVE39AItW19YYci00SJX0TS3tGWXgAWzVZT/3gr5kY6+Ok6f+pQ4heRtHe8NZL4VeP/bcuDkQx1nT91KPGLSNo72tpDZoYxrywv7FASTnFeNjVl+extUOJPFUr8IpL2jrX2UVOWT1am/kucyMq56tmfSvQrF5G0d6y1l0Xq0X9ay6uKONTcw9DIaNihyDRQ4heRtHespYcFur5/WiurihkcGeVoS0/Yocg0UOIXkbTW2T9EW+8Qi5T4T2ts6N69Dd0hRyLTQYlfRNLasRb16J/KeZVFZJhu6UsVSvwiktbGbuVTU//p5WVnsnhOIfvUsz8lKPGLSFo7OnYPvzr3TWp5VRH7mpT4U4ESv4iktWOtvcwqyKYkLzvsUBLayqpijpzsoX9oJOxQ5Bwp8YtIWjvW0svCORqqdyor5hYz6nCwWR38kp0Sv4iktdq2XubPyg87jIS3MujZr4F8kp8Sv4ikrdFRp66jn/llSvxTWVxeSHam6Za+FKDELyJp62TPAIPDo9Soxj+l7MwMlpYXsV81/qSnxC8iaauuvR+AeaVK/LFYMbdY9/KnACV+EUlbde19AMxTU39MVlYVUdvWR/fAcNihyDlQ4heRtHWiLZL41dQfm+VBBz819yc3JX4RSVsn2vsoys2iJC8r7FCSwopTiV8d/JKZEr+IpK269j5qyvIxs7BDSQoLZxeQm5WhW/qSnBK/iKStE+19zCvLCzuMpJGZYSyrKGJfk2r8yUyJX0TSVl17nzr2naEVVbqlL9kp8YtIWuodHKatd0gd+87Q8qpi6jv66ewfCjsUOUtK/CKSlsZu5atRjf+MqINf8lPiF5G0dGJs8B4l/jOyoqoI0C19yUyJX0TSkmr8Z2fBrALysjPYpxp/0lLiF5G0dKKtj8wMo7I4N+xQkkpGhrG8spj9TarxJyslfhFJS3XtfcwtySMrU/8NnqnlVUW6lz+J6RcvImmpNhi8R87ciqpiGjsH6OhTz/5kpMQvImmpvqOPag3ec1bUwS+5xTXxm9nVZrbXzA6Y2R0TzDczuzOY/5KZbZyqrJl9wsxOmNkLwevaeO6DiKQed6exY4BqPY73rCyvjNzSpw5+ySluid/MMoEvANcAa4AbzGzNuMWuAZYHr1uAu2Is+6/uviF4PRyvfRCR1NTaM8jgyChzS9Sx72zUlOVTkJOp6/xJKp41/s3AAXc/5O6DwH3AdeOWuQ64xyOeBsrMrDrGsiIiZ6W+I3IP/1zV+M9KpGd/kXr2J6l4Jv4a4HjU59pgWizLTFX29uDSwFfMbNb0hSwi6aAhSPzVpbrGf7aWVxWrqT9JxTPxT/ScS49xmcnK3gUsAzYA9cC/TLhxs1vMbKuZbW1ubo4pYBFJDw2dYzV+Jf6ztaKqiOauAdp7B8MORc5QPBN/LbAg6vN8oC7GZU5b1t0b3X3E3UeB/yByWeC3uPuX3H2Tu2+qqKg4px0RkdTS0NFPZoZRXqRr/GdreZU6+CWreCb+LcByM1tiZjnA9cCD45Z5EHhX0Lv/EqDD3esnKxv0ARjzZmBHHPdBRFJQfUc/VcW5ZGZM1LgosVhxKvHrOn+yyYrXit192MxuBx4BMoGvuPtOM7s1mH838DBwLXAA6AVunqxssOp/NLMNRJr+jwDvj9c+iEhqauzsVzP/OZpXmkdRbpbu5U9CcUv8AMGtdg+Pm3Z31HsHbou1bDD9ndMcpoikmfqOPlbOLQ47jKRmZpxXWaSm/iSkkftEJO00dPQzt0S38p2rFVW6pS8ZKfGLSFrp6h+iZ3BEt/JNgxVVxZzsHqS1Rz37k4kSv4iklbF7+KuU+M/ZWM/+vQ2q9ScTJX4RSSv1Grxn2qyeO5b4O0OORM6EEr+IpJWxGv/cEiX+c1VRnMvswhz2qMafVJT4RSStjI3aV6XEf87MjFVzi9ldrxp/MlHiF5G0Ut/RT3lRDjlZ+u9vOqyaW8Lexi5GRsePyC6JSr98EUkrDR19GrxnGq2uLqZ/aJSjLT1hhyIxUuIXkbTS0Dmge/in0erqEgBd508iSvwiklYaO/upKtHDeabLeZVFZBi6zp9ElPhFJG0MDI/Q2jOoHv3TKC87k6UVReyuV40/WSjxi0jaaO4aANSjf7qtmlvMHt3LnzSU+EUkbTR2RhJ/hZr6p9Xq6hJq2/ro7B8KOxSJgRK/iKSNprF7+ItV459Oq+Zq6N5kosQvImmj6VRTv2r802ntvFIAdpzoCDkSiYUSv4ikjcbOfrIzjVkFOWGHklKqSnIpL8phxwld508GSvwikjYaOweoLM4jI8PCDiWlmBnrakpV408SSvwikjaauvqpVDN/XJxfU8r+pi76BkfCDkWmoMQvImmjsbNfHfviZF1NKaMOu3VbX8JT4heRtNHYOaAaf5ysq1EHv2ShxC8iaaF/aISOviEN3hMn80rzmF2Yw/ZaJf5Ep8QvImmhKRi8p7JYNf54ONXBr05N/YlOiV9E0kJjVzB4j2r8cXN+TQn7G7voH1IHv0SmxC8iaWGsxq/EHz/r5pUyPOp6RG+CU+IXkbTQODZcrzr3xc0FC8oAePF4e6hxyOSU+EUkLTR29ZOTlUFpfnbYoaSseaV5VJXk8tzRtrBDkUko8YtIWmjqHKCqJBczjdoXL2bGyxbNUuJPcEr8IpIWGjv7qdTgPXG3ceEsTrT3nbq0IolHiV9E0kJjZ7+u78+AjYtmAbBNtf6EpcQvImmhKXhAj8TX2nkl5GRlqLk/gSnxi0jK6xkYpmtgWLfyzYDcrEzOryll2zEl/kQVU+I3s++Y2e+amU4URCTpNHWN3cOvpv6Z8LJFs9hxolMD+SSoWBP5XcAfAPvN7NNmtiqOMYmITKumTo3aN5M2LpzF4MgoO+s0bn8iiinxu/tP3P0dwEbgCPComT1lZjebmW6KFZGE1qga/4x6WdDB75nDrSFHIhOJuenezOYA7wb+EHge+ByRE4FH4xKZiMg0GavxV6hz34yoKM5l1dxifnngZNihyARivcb/APBzoAB4g7u/0d3vd/cPAUWTlLvazPaa2QEzu2OC+WZmdwbzXzKzjWdQ9k/NzM2sPJZ9EJH01djZT152BiV5WWGHkjYuO6+cLUfadJ0/AcVa4/+yu69x979393oAM8sFcPdNExUws0zgC8A1wBrgBjNbM26xa4DlwesWIn0JpixrZguAq4BjMcYvImmssXOAqpI8jdo3gy4/r5zB4VG2HlHv/kQTa+L/1ATTfjVFmc3AAXc/5O6DwH3AdeOWuQ64xyOeBsrMrDqGsv8K/DngMcYvImmssbOfKjXzz6jNS2aTlWH88qCa+xPNpO1eZjYXqAHyzexCYOx0uYRIs/9kaoDjUZ9rgYtjWKZmsrJm9kbghLu/ONnZu5ndQqQVgYULF04RqoiksqauAdbOKwk7jLRSmJvFxoWzdJ0/AU11wet1RDr0zQc+EzW9C/iLKcpOlJXH19BPt8yE082sAPhL4Hem2Dbu/iXgSwCbNm1Sy4BImnJ3Gjv7uXJVZdihpJ3Lzivnsz/dR3vvIGUFOWGHI4FJm/rd/WvufgXwbne/Iur1Rnd/YIp11wILoj7PB+piXOZ005cBS4AXzexIMH1b0DIhIvJbugeG6R0c0a18IbjsvDm4w1MHW8IORaJM1dR/o7v/N7DYzP54/Hx3/8wExcZsAZab2RLgBHA9kUGAoj0I3G5m9xFpyu9w93oza56orLvvBE6dtgfJf5O7qy1JRCb061H7dI1/pm1YUEZZQTY/3tnAtedXhx2OBKZq6i8M/j3tLXun4+7DZnY78AiQCXzF3Xea2a3B/LuBh4FrgQNAL3DzZGXPNAYRkcZT9/Crxj/TsjIzuGp1FT/a0cDg8Cg5WRr1PRFMmvjd/YvBv588m5W7+8NEknv0tLuj3jtwW6xlJ1hm8dnEJSLpo6lTNf4wXXP+XP7nuVp+efAkV6xUP4tEEOsAPv9oZiVmlm1mPzWzk2Z2Y7yDExE5V40apz9Ul51XTnFuFj/a3hB2KBKItd3ld9y9E3g9kY53K4A/i1tUIiLTpLFzgMKcTIpyNWpfGHKzMrlydSU/3tXA8Mho2OEIsSf+sQfxXAvc6+568oKIJIXGrn7V9kN29dq5tPUO8awe2pMQYk38PzCzPcAm4KdmVgH0xy8sEZHp0dTZT6Vu5QvVq1dWUpSbxbefqw07FCH2x/LeAVxK5Na5IaCH3x5+V0Qk4YyN0y/hyc/J5M0X1vDQ9nraegbDDiftncm9FauBt5vZu4C3EMPoeSIiYXJ3mrr6qdStfKF7xyULGRweVa0/AcTaq//rwD8DlwMXBa8Jn8onIpIoOvuG6R8aVY0/AayaW8KmRbP4xjNHGR3VKOphirWb6yZgTXDfvYhIUmjQrXwJ5R2XLOQj97/ILw+e5BXLK8IOJ23F2tS/A9B4+CKSVMbu4Z9bqsSfCK5ZV01FcS53/nQ/qkeGJ9bEXw7sMrNHzOzBsVc8AxMROVenavzFSvyJIC87k//zmuVsOdLGT3c3hR1O2oq1qf8T8QxCRCQemoLEr9v5EsfbL1rAf/7iMP/woz1csaqSzIyJnsIu8RTr7XxPAkeA7OD9FmBbHOMSETlnDZ39lBVkk5edGXYoEsjOzODPXreS/U3d3LflWNjhpKVYe/W/D/g28MVgUg3wvTjFJCIyLRo7B5irjn0J55p1c7l06Rw+9dBuDjR1hx1O2on1Gv9twGVAJ4C77wf0mCURSWiNnf1UKvEnHDPjs9dvID8nk9u/uY3+oZGwQ0orsSb+AXc/NdySmWUB6pIpIgmtsbOfKg3ek5CqSvL4l7euZ09DF3/yrRcZ0gN8Zkysif9JM/sLIN/MrgL+B/hB/MISETk3I6NOc9eAbuVLYFesquQvr13N/26v54Pf2MbAsGr+MyHWxH8H0AxsB94PPAx8PF5BiYicq5PdA4w6aupPcO975VI++ca1PLqrkbd98WkONHWFHVLKi+l2PncfNbPvAd9z9+b4hiQicu5ODd6jxJ/wbnr5YiqLc/mL727n2jt/wQdetYz3vmIJJXnZUxeWMzZpjd8iPmFmJ4E9wF4zazazv56Z8EREzk5Dx9hwvbrGnwyuOb+aRz7ySq5aXcXnfrqfyz/9GJ/7yX46+4fCDi3lTNXU/2Eivfkvcvc57j4buBi4zMw+Eu/gRETOVmPXAKAafzKpLM7jC+/YyEMfupyLl87hX3+yj8s//Rh3/nQ/XToBmDZTJf53ATe4++GxCe5+CLgxmCcikpAaO/rJzDDmFKnGn2zW1ZTyH+/axEMfupzNS2bzmUf3cfk/PM5//uKwnuw3DaZK/NnufnL8xOA6vy6+iEjCauzsp6IoV0PCJrF1NaV8+aaL+MHtl7N+QRl/99Au3nfPVtp7B6cuLKc1VeKf7OjqyItIwmro7Nf1/RRx/vxSvnbzRXzyjWv52f5mfu/fn6KleyDssJLWVIl/vZl1TvDqAs6fiQBFRM5GU+cAVbq+nzLMjJtevpj/fu/FnGjv4+avbqF7YDjssJLSpInf3TPdvWSCV7G7q6lfRBJWpMavxJ9qLl46h39/x0Z21nVy+ze34a5r/mcq1gF8RESSRv/QCB19Qxq1L0W9ZnUVf/36NTyxt5n/ea427HCSjhK/iKScscF7KjVOf8p65yWL2LxkNp96aBdNwfctsVHiF5GU09gZ3MOvGn/KysgwPv1759M/PMonfrAz7HCSihK/iKSchs6xUfuU+FPZ0ooiPvCqZTy8vYHd9Z1hh5M0lPhFJOU0KfGnjfdctoTCnEzueuJg2KEkDSV+EUk5DR395GVnUJIX03PIJImVFmRz46WLeOilOo6c7Ak7nKSgxC8iKaexK3IPv5lG7UsH7718CVmZGXzxZ6r1x0KJX0RSTmOH7uFPJ5XFebzlZfP5zrYTdPTpYT5TUeIXkZTT2KXEn27evmkBg8Oj/HB7fdihJLy4Jn4zu9rM9prZATO7Y4L5ZmZ3BvNfMrONU5U1s78Lln3BzH5sZvPiuQ8iklzcnYaOfuZqnP60csH8UpZWFPLA8yfCDiXhxS3xm1km8AXgGmANcIOZrRm32DXA8uB1C3BXDGX/yd0vcPcNwEPAX8drH0Qk+XT2DTMwPKoaf5oxM35/43yePdzK8dbesMNJaPGs8W8GDrj7IXcfBO4Drhu3zHXAPR7xNFBmZtWTlXX36Js1CwEN1CwipzR26Va+dPWmC2sA+K5q/ZOKZ+KvAY5Hfa4NpsWyzKRlzez/mtlx4B2cpsZvZreY2VYz29rc3HzWOyEiyaWhQ4k/XdWU5XPJ0tl89/kTenjPJOKZ+Ce6j2b8N3G6ZSYt6+5/6e4LgG8At0+0cXf/krtvcvdNFRUVMYYsIslubJz+uUr8aen1F8zj8MkeDjZ3hx1Kwopn4q8FFkR9ng/UxbhMLGUBvgn8/jlHKiIp49QDetS5Ly1duaoSgMf2NIUcSeKKZ+LfAiw3syVmlgNcDzw4bpkHgXcFvfsvATrcvX6ysma2PKr8G4E9cdwHEUkyjZ0DlBVkk5edGXYoEoJ5ZfmsmlvMT3cr8Z9O3MazdPdhM7sdeATIBL7i7jvN7NZg/t3Aw8C1wAGgF7h5srLBqj9tZiuBUeAocGu89kFEkk9DZz9VxWrmT2evWV3J3U8eoqNviNL87LDDSThxHcja3R8mktyjp90d9d6B22ItG0xX076InFZTZz9VehxvWrtyVSVfePwgP9vXzBvWa6iX8TRyn4iklEiNX9f309mGBbOYVZDN47rOPyElfhFJGSOjTnPwgB5JX5kZxhUrK3l8bxOjo7qtbzwlfhFJGU1d/Yw6zFVTf9q7fHk5bb1D7G3sCjuUhKPELyIpo649citfTVl+yJFI2C5eOgeApw+1hBxJ4lHiF5GUUd/RB0B1mWr86a6mLJ8Fs/N55lBr2KEkHCV+EUkZde2RxD9PNX4BLl4yh2cOt+g6/zhK/CKSMura+ynKzaIkT/duC1yydA5tvUPsb9LwvdGU+EUkZdR39FGtjn0SuHjJbEDX+cdT4heRlFHX3q9mfjllwewCasryeeawEn80JX4RSRn1HX3MU8c+iXLx0tk8fahVj+mNosQvIimhf2iEk92DVJeqxi+/tnnxbFp7BjnS0ht2KAlDiV9EUkJDR+QefjX1S7QNC8sAeP5YW7iBJBAlfhFJCXXBPfzz1LlPoiyvLKYwJ5MXjreHHUrCUOIXkZQwNmpftWr8EiUzw1i/oIznj7WHHUrCUOIXkZRQHwzeo9v5ZLwNC8rYXd9J/9BI2KEkBCV+EUkJdR39zCnMIS87M+xQJMFcuHAWw6POjhMdYYeSEJT4RSQl1LX3aYx+mdCGBWUAau4PKPGLSEqo7+hjnm7lkwlUFOcyf1a+OvgFlPhFJCXUa9Q+mcSGBWW6pS+gxC8iSa+zf4iugWF17JPT2rCgjLqOfpq6+sMOJXRK/CKS9GpbIz36588qCDkSSVQXzC8DUAc/lPhFJAUcb4sMx7pgtpr6ZWJr5pVgBjtOdIYdSuiU+EUk6R1vDRK/avxyGkW5WSwpL2S7avxK/CKS/Grb+ijKzaKsIDvsUCSBrZtXyk4lfiV+EUl+x1t7mT8rHzMLOxRJYOfXlFLX0U9L90DYoYRKiV9Ekt7xtl4WzFYzv0xuXU0pADvq0vs6vxK/iCQ1d+d4a5+u78uU1taUAOrZr8QvIkmtpWeQvqER9eiXKZXkZbN4TgHba5X4RUSSlnr0y5lYW1PKjjolfhGRpHW8LTJ4j67xSyzOrymltq2Ptp7BsEMJjRK/iCS1sRr//Flq6peprZ0Xuc6/uz59O/gp8YtIUqtt62VOYQ6FuVlhhyJJYHV1JPHvUuIXEUlOx1v7mK9mfolReVEulcW5SvwiIsnqeFsvC9TML2dgzbwSdqXxvfxxTfxmdrWZ7TWzA2Z2xwTzzczuDOa/ZGYbpyprZv9kZnuC5b9rZmXx3AcRSVwjo05de5869skZWVNdwoGmbgaGR8IOJRRxS/xmlgl8AbgGWAPcYGZrxi12DbA8eN0C3BVD2UeBde5+AbAP+Fi89kFEElt9Rx9DI65b+eSMrJlXwvCoc6CpO+xQQhHPGv9m4IC7H3L3QeA+4Lpxy1wH3OMRTwNlZlY9WVl3/7G7Dwflnwbmx3EfRCSBHTkZ6dG/pLww5EgkmZzq4Jemzf3xTPw1wPGoz7XBtFiWiaUswHuAH060cTO7xcy2mtnW5ubmMwxdRJLBoZORGtuyCiV+id3iOYXkZ2embQe/eCb+iR6T5TEuM2VZM/tLYBj4xkQbd/cvufsmd99UUVERQ7gikmwONfdQmJNJRXFu2KFIEsnMMFZVF6vGHwe1wIKoz/OBuhiXmbSsmd0EvB54h7uPP5kQkTRx+GQPSyoK9TheOWNrqkvYVd9JOqaQeCb+LcByM1tiZjnA9cCD45Z5EHhX0Lv/EqDD3esnK2tmVwMfBd7o7r1xjF9EEtyhk90sKS8KOwxJQmvmldDVP8yJ9r6wQ5lxcUv8QQe824FHgN3At9x9p5ndama3Bos9DBwCDgD/AXxwsrJBmc8DxcCjZvaCmd0dr30QkcQ1MDxCbVufOvbJWUnnDn5xHePS3R8mktyjp90d9d6B22ItG0w/b5rDFJEkdKylF3d17JOzs2puMWaRoXt/Z+3csMOZURq5T0SS0qGTPYBu5ZOzU5CTxZLywrSs8Svxi0hSOtQcSfyLlfjlLK2pLmF3gxK/iEhSOHyym/KiXEryssMORZLU6uoSjrf20dE3FHYoM0qJX0SS0uGTPSzV9X05B2vmRTr47UmzgXyU+EUkKR0+2cNSNfPLOVg71rNfiV9EJLF19A1xsntQHfvknFQU51JelJN2HfyU+EUk6Yw9VW1ZhQbvkbNnZqxOww5+SvwiknR2B02zq6qLQ45Ekt2a6hL2NXQzNDIadigzRolfRJLOnoZOivOyqCnLDzsUSXJr5pUwODLKwebusEOZMUr8IpJ09tR3sXpuiR7OI+dsTRoO3avELyJJxd3Z09ClZn6ZFkvKC8nNylDiFxFJVLVtfXQPDLNqbknYoUgKyMrMYOXc4rTq4KfELyJJZU9DF6COfTJ91lSXsKuuk8hz41KfEr+IJJWxUdZWVinxy/RYM6+Ett4hGjr7ww5lRijxi0hS2dPQxaI5BRTmxvWp4pJG0q2DnxK/iCSV3Q2drJqr2r5Mn1VB4t+dJkP3KvGLSNLoGxzhyMkedeyTaVWUm8WiOQVpM2a/Er+IJI09DZ2MOqxWxz6ZZmMd/NKBEr+IJI1tx9oBuHDhrHADkZSzprqEIy29dA8Mhx1K3Cnxi0jS2HasjZqyfKpK8sIORVLM6uA6/540aO5X4heRpPH80TYuXFgWdhiSgtbMS58Ofkr8IpIU6jv6qOvo52WL1Mwv06+6NI+yguy06OCnxC8iSWHb0XYANur6vsSBmaVNBz8lfhFJCtuOtZGblXHqWqzIdFtTXcKehi6GR0bDDiWulPhFJClsO9bGBfNLycnSf1sSH6urSxgYHuVIS0/YocSV/oJEJOH1D42w40QHG3V9X+JorIPfzhRv7lfiF5GE91JtB0Mjruv7ElfLKorIycxI+Q5+SvwikvCe3NdEZoZx6bI5YYciKSwnK4PlVUUp38FPiV9EEt7je5p52aJZlORlhx2KpLjV1SUpfy+/Er+IJLSGjn521XdyxcrKsEORNLCmuoST3YM0dfWHHUrcKPGLSEJ7cl8TAFesqgg5EkkHpzr4nUjdWr8Sv4gktMf3NFNdmsfKKj2RT+JvXU0pZvBibXvYocSNEr+IJKyhkVF+ceAkr15ZiZmFHY6kgaLcLJZXFvHi8fawQ4kbJX4RSVhPH2qhe2CYV69UM7/MnPXzy3ixtgN3DzuUuIhr4jezq81sr5kdMLM7JphvZnZnMP8lM9s4VVkze6uZ7TSzUTPbFM/4RSRc336ulpK8LF61QolfZs76BWW09gxS29YXdihxEbfEb2aZwBeAa4A1wA1mtmbcYtcAy4PXLcBdMZTdAfwe8LN4xS4i4evoHeKHOxp404U15GVnhh2OpJH188uA1L3OH88a/2bggLsfcvdB4D7gunHLXAfc4xFPA2VmVj1ZWXff7e574xi3iCSAB188weDwKG/btCDsUCTNrJxbTE5WRspe549n4q8Bjkd9rg2mxbJMLGVFJIXdv/U4a6pLWFdTGnYokmZysjJYO6+EF493hB1KXMQz8U/UBXd8T4nTLRNL2ck3bnaLmW01s63Nzc1nUlREQrbjRAc7TnTy9otU25dwrJ9fxvYTHSn5iN54Jv5aIPqvdj5QF+MysZSdlLt/yd03ufumigp1DBJJJp/9yT5K8rJ404Vq6JNwbFhQRt/QCPubusMOZdrFM/FvAZab2RIzywGuBx4ct8yDwLuC3v2XAB3uXh9jWRFJQVuPtPKT3U3c+upllOZrbH4Jx4YFZQBsO9YWbiBxELfE7+7DwO3AI8Bu4FvuvtPMbjWzW4PFHgYOAQeA/wA+OFlZADN7s5nVApcC/2tmj8RrH0RkZrk7//CjPVQW53Lzy5eEHY6ksUVzCigvymXrkdRL/FnxXLm7P0wkuUdPuzvqvQO3xVo2mP5d4LvTG6mIJIKHtzew5Ugbf/emdeTn6BY+CY+ZcdHiWTx7uDXsUKadRu4TkYRwrKWXOx54ifXzS7lenfokAVy0eDYn2vuoa0+tgXyU+EUkdAPDI9x+7zYM+PwfbCQ7U/81SfguWjwbgK1HU6u5X39dIhKqvsERPvDf23iptoN/eut6FswuCDskEQBWVxdTmJPJlhRr7o/rNX4Rkcm09Qxyy9e3svVoG5960zpet3Zu2CGJnJKVmcHGRbPYciS1Er9q/CIy49ydh16q46p/fZIXjrfzbzdcyI2XLAo7LJHfsmnRbPY2dtHRNxR2KNNGNX4RmTGjo85PdjfyxZ8d4rmjbVwwv5R73nMxa+aVhB2ayIQuWjwLd3juaCtXrqoKO5xpocQvInHl7mw71s5DL9Xx8PZ6GjsHmD8rn7970zpuuGgBWerIJwls46JZ5GRl8Iv9LUr8IiKnMzA8wjOHWnlsTxOP7mrkRHsfOZkZvGplBW/aUMPr1lYp4UtSyMvO5OIls/n5/tR55osSv8TNyKjT0TdE/9AIg8OjDI2MMjgyimFkZxpZmRlkZxrZmRlkZRgFOVnkZWdgNtEzmlLb0Mgog8PBa2QUA0oLssnNSp5BbOo7+nh8TzOP7WniqYMn6R0cITcrg8vOK+ePr1rBVWurKMnTELySfF6xvJz/9/Ae6jv6qC7NDzucc6bEL2eto2+I/Y1dHG3p5VhrL8dbezne1ktL9yCtvYN09A3hZ/RMRcjMMApzMinOy6YoN4uivKxT/5bmZ1NemMPswhzmFOUypyiHOYW5VBbnUlaQnfAnDG09g+xp6GJPQyeHT/ZQ195HbVsfJ9r76OofnrBMQU4mZfnZzCnKZdGcAhbPKWRxeSFLyiPvZxfmhLbf/UMjvHC8nZ/ta+bxvc3sru8EoKYsn9/bWMOVqyq5dGm5RuCTpPeK5RXAHn6+/yRv25T8g0sp8UtMOvqG2HasjeePtbOrrpPd9Z2ciBrNygzmleYzf1Y+a+aVMLswh1kFOcwqyCY/J5OcrAyyMyMvd2doxBkeHWVoxBkaGWV4xOkbGqG7f5jugWG6+ofpHhiie2CY9t5Bjrf20tE3RFvvIKMTnEwU5mSyYHYB82cVMH9WPgtmF7BgVj6LywtZOLuAvOyZSz79QyMcau5hX2PXqUS/p76Lhs7+U8sU52VRUxY5Xhcvmc2colxysjLIycwgJytyjDr6hmjvHaK9b4imrgG2n+jghzsaGIk6AMV5WSycXcCiOQUsnF3IojkFLJpdwILZBVQU507bfo+MOsdbeznQ1M3zx9t49nArLx7vYHBklMwMY9OiWdxxzSquXFXJ8sqihD8JEzkTq+YWU1Gcq8Qvqe1Eex9bj7Sy5UgrW4+0sbexC3fIMFhaUcTGRbN4xyULWT23hMXlhcwry5uRZumRUae9d5CWnkFaugdp6RmgoaOf2rY+att6qW3r5VcHT9IzOPIb5eaW5LFwTgGL5xSwaM5Ygixk4ZyCs3oC3Oio09Q1wIn2SI39QFM3+xq62NfUxZGTPadOTrIzjWUVRVy6bA6r5hazurqEVdXFVBTlnlVyHBwepbatl6MtvRw+2cORlh6OtvSyu76LR3c1MjTym2dFRblZQQtJDnOC1pKi3GwKcjLJz8mkICeTrIxfx+FA98AwHb2Rk4623kGOtfZy6GQPg8OR55JnZhjrakq5+bLFbF4ym02LZ+spepLSzIxXLC/nib3NjI46GRnJfWKrxC9ApJb6zOFWntjbxBN7mzl8sgeIJI4LF5Zx7fnVbFo0i/ULyijMDe9nk5lhQTN/Lpymg62709Y7xLHWXo629HCspZcjLb0ca+3h8b3NNHfV/sbypfnZzCnMobQgm7L8bErys8kM/rANw3F6Bobp6Buisy/yb1NX/28kWTNYPKeQ5ZVF/O751SyvKmZlVTFLygvJyZq+Tmw5WRksrShiaUURV4ybNzLq1LX3nbrsEn1y1NozyIn2fraf6KB3YISeweEJW06it1OWn01pfjbzZ+XziuXlLK8sZlllEavmFof6GxAJwyuXV/DAthPsqu9kXU1p2OGcE/31prGhkVGe3NvMd58/wWN7mugbinTGunTZHN516SI2L5nNqrklp5JgsjAzZge127FnakfrGRgOTgoiJwa1bX20BX0STnYPcrC5h1H33+ifUJSbRUl+FvPK8lg1t5jKkjxqZuVTU5ZHTVmkqX0mLydMJDPDIpc4Yhjy1t0ZGB6ld3CEUf/tVoKw90Uk0Vy+vBwzeHRXoxK/JJ89DZ3c+8wxfvBSPa09g8wuzOEtL5vPlasruXTpnJT/T78wN4vV1SWsrk7fQWPMjLzszJT/rkWmS3lRLpsXz+ZHOxr4yFUrwg7nnCjxp5GnDp7kricO8vP9J8nJyuCq1VW8+cIaXrWyQk9DExGZwrXnV/M3D+7kQFM351UWhR3OWVPiTwMv1bbzDz/awy8PtFBZnMufvW4l77h4IWUFOWGHJiKSNK5eN5e/eXAnP9xez4deszzscM6aEn8Ka+8d5B8f2cu9zx5jdkEOf/X6Nbzj4oVq3hUROQtVJXlsWjSLh3c0KPFL4nl0VyMfe2A7bb2DvOeyJXz4tcsp1qhpIiLn5Op1c/nU/+7m8MkelpQXhh3OWdGF3RTTOzjMn3/7Rd53z1YqinP5we2X81evX6OkLyIyDa45vxqA779wIuRIzp4Sfwo50NTFdZ//Jf/zXC23XbGM7992mR53KiIyjWrKIuNa3PfscYZHRsMO56wo8aeIx/c08aYvPEVrzyD3vGczf/a6VdM6cIyIiETceMkiGjr7eWxPU9ihnBVlhiTn7nzlF4d579e2sHB2AQ/90eXBAyVERCQeXrOqkqqSXL7xzLGwQzkrSvxJbGhklI9/bwd/+9AuXru6im9/4NKUeGSkiEgiy8rM4PqLFvKz/c0ca+kNO5wzpsSfpDp6h3j3fz3LN545xgdevYy7b3wZBTm6SUNEZCbcsHkhGWb85y8OhR3KGVPiT0KHT/bw5n//Jc8ebuWf3nIBH716VdI/LUpEJJnMLc3jbZvm881nj1Hblly1fiX+JPOrgy286Qu/pK13kG/84SW8NQWeDS0ikow+dOVyDOPOn+4PO5QzosSfRO7fcox3/uczVBTn8r3bLmPzktlhhyQikrbmleVz4yWL+PZztRxs7g47nJgp8SeB/qERPvbAS3z0O9u5dNkcHvjgy1k0JzlHjBIRSSUfvGIZBTlZfPy7Oxgd9akLJAAl/gR3vLWXt9z9FPc+e5zbrljGV2/eTIlG4RMRSQjlRbn81etX86tDLfzXU0fCDicm6gaewB7f08SH73+BUXe+/K5NvHZNVdghiYjIOG/btIBHdzXyDz/aw+XnlbNybnHYIU1KNf4E1NU/xMce2M7NX91CTVk+D33ociV9EZEEZWb8/e9dQEleFu/56hZOtPeFHdKklPgTyOio873nT3DVZ37G/VuO8f5XLtX1fBGRJFBRnMtXb95MZ98QN375GZq6+sMO6bSU+BOAu/PT3Y28+a6n+PD9L1BRnMt3PvByPnbtavKyM8MOT0REYrCuppT/uvkiGjr6eeO/RcZaSURxTfxmdrWZ7TWzA2Z2xwTzzczuDOa/ZGYbpyprZrPN7FEz2x/8Oyue+xBPbT2DfPWXh7n6sz/nvV/bysmuAf75rev5/m2XceHCpN0tEZG0tWnxbP7n1kvJzc7ghv94mv/38G7aegbDDus3mHt8bj8ws0xgH3AVUAtsAW5w911Ry1wLfAi4FrgY+Jy7XzxZWTP7R6DV3T8dnBDMcvePThbLpk2bfOvWrdO/k2doaGSU3fWdPHu4lcf3NvHs4VaGRpx1NSW857IlvGH9PLIz1QgjIpLsuvqH+OQPdvGdbbUUZGfy1k0LeMP6ai5cMGtGRlo1s+fcfdNE8+LZq38zcMDdDwVB3AdcB+yKWuY64B6PnH08bWZlZlYNLJ6k7HXAq4PyXwOeACZN/PEwMuoMjYwyODLK8Ejk/cDQKB19Q3T0DdHZP0RLzyDHWno40tLL0eDfweHI85uXVxbxnsuXcN36GtbMK5np8EVEJI6K87L557eu5/2vXMqdjx3gm88e46tPHaE0P5v1C8pYWVXE3NJ85pbkMbc0l3ll+TP2kLV4Jv4a4HjU51oitfqplqmZomyVu9cDuHu9mVVOZ9BT+cyj+/i3x/YTa0NJblYGi+YUsGhOIa9aUcH6BWVsXDiLeWV6ip6ISKpbXlXMv91wIV39Q/x0dxNPH2rhhePtPHOohYGgIgiwam4xP/rwK2ckpngm/onaMsany9MtE0vZyTdudgtwS/Cx28z2jlukHDh5Jus8W/tmYiOJbcaOdZrTcZ4ZOs4zI62O81HAPjKtq1x0uhnxTPy1QPQTZOYDdTEukzNJ2UYzqw5q+9VA00Qbd/cvAV86XXBmtvV01z9keulYzwwd55mh4zwzdJzjJ549ybYAy81siZnlANcDD45b5kHgXUHv/kuAjqAZf7KyDwI3Be9vAr4fx30QERFJKXGr8bv7sJndDjwCZAJfcfedZnZrMP9u4GEiPfoPAL3AzZOVDVb9aeBbZvZe4Bjw1njtg4iISKqJ2+18ic7MbgkuB0ic6VjPDB3nmaHjPDN0nOMnbRO/iIhIOtJoMSIiImkkJRO/meWZ2bNm9qKZ7TSzTwbTTzvcr5l9LBgeeK+ZvS686JOPmWWa2fNm9lDwWcc5DszsiJltN7MXzGxrME3HepoFA4l928z2mNluM7tUx3n6mdnK4Lc89uo0sw/rWMdfSiZ+YAC40t3XAxuAq4O7Bu4Afuruy4GfBp8xszVE7hxYC1wN/HswbLDE5v8Au6M+6zjHzxXuviHqNicd6+n3OeBH7r4KWE/kt63jPM3cfW/wW94AvIxIB+/vomMddymZ+D2iO/iYHbycyHC/Xwumfw14U/D+OuA+dx9w98NE7jLYPHMRJy8zmw/8LvDlqMk6zjNHx3oamVkJ8ErgPwHcfdDd29FxjrfXAAfd/Sg61nGXkokfTjU/v0BkgJ9H3f0Zxg33C4wN93u6oYNlap8F/hwYjZqm4xwfDvzYzJ4LRqYEHevpthRoBv4ruHz1ZTMrRMc53q4H7g3e61jHWcomfncfCZqQ5gObzWzdJIuf8xDB6cjMXg80uftzsRaZYJqOc+wuc/eNwDXAbWY22cDeOtZnJwvYCNzl7hcCPQRNzaeh43yOgkHa3gj8z1SLTjBNx/ospGziHxM00z1B5JpQYzDML+OG+41leGH5bZcBbzSzI8B9wJVm9t/oOMeFu9cF/zYRuRa6GR3r6VYL1AYthADfJnIioOMcP9cA29y9MfisYx1nKZn4zazCzMqC9/nAa4E9nH643weB680s18yWAMuBZ2c06CTk7h9z9/nuvphIU91j7n4jOs7TzswKzax47D3wO8AOdKynlbs3AMfNbGUw6TVEHgeu4xw/N/DrZn7QsY67eD6kJ0zVwNeCHp8ZwLfc/SEz+xUTDPcbDCX8LSJ/4MPAbe4+ElLsqWDCYZV1nM9JFfBdM4PI3+033f1HZrYFHevp9iHgG0ET9CEiQ4lnoOM87cysALgKeH/UZP3/EWcauU9ERCSNpGRTv4iIiExMiV9ERCSNKPGLiIikESV+ERGRNKLELyIikkaU+EVSmJnNNbP7zOygme0ys4fNbMU5rO+rZvaW4P2XgwenYGZ/MUmZsacKvmRmT5rZoim2sdjM/iDq8yYzu/NsYxaR36TEL5KiLHLT/3eBJ9x9mbuvAf6CyJgA0cud1RPO3P0P3X1X8PG0iT9whbtfQGQUzY9Psexi4FTid/et7v5HZxOjiPw2JX6R1HUFMOTud49NcPcX3P3nZvZqM3vczL4JbA8eavVPZrYlqJm/HyInD2b2+aC14H/59QNTMLMngtr4p4H84Jnq35gipl8RPFglqNn/3My2Ba+XB8t8GnhFsL6PBLE+FJT5hJl9Jdj2ITM7dUJgZn9lZnss8gz3e83sT8/9EIqknlQduU9EYB0w2QOUNgPr3P1w8LS/Dne/yMxygV+a2Y+BC4GVwPlEWgp2AV+JXom732FmtwcPxZrK1cD3gvdNwFXu3m9my4kM27qJyENx/tTdXw9gZq8et45VRE5qioG9ZnYXsB74/SDeLGDbFPsukraU+EXS17PBc80hMvb/BWPX74FSImOhvxK4Nxgatc7MHjvLbT1uZlVEkv1YU3828Hkz2wCMALH2Pfhfdx8ABsysicgJyeXA9929D8DMfnCWcYqkPDX1i6SuncDLJpnfE/XegA+5+4bgtcTdfxzMm45xva8AFgUx/W0w7SNAI5Ha+iYgJ8Z1DUS9HyFSgZnoka0iMgElfpHU9RiQa2bvG5tgZheZ2asmWPYR4ANmlh0styJ4CuDPiDwRLTN4ROoVp9nW0FjZ0wlq4x8G3mVms4m0KtS7+yjwTmCsk2EXkWb8M/EL4A1mlmdmRcDvnmF5kbShxC+SojzyBK43A1cFt/PtBD7BxM8w/zKR6/fbzGwH8EUiNenvAvuB7cBdwJOn2dyXgJem6tzn7vVEruXfBvw7cJOZPU2kmX+sBeIlYNjMXjSzj8S4r1uIPLb1ReABYCvQEUtZkXSjp/OJSEowsyJ37w4e9foz4BZ33xZ2XCKJRp37RCRVfCkYUCgP+JqSvsjEVOMXERFJI7rGLyIikkaU+EVERNKIEr+IiEgaUeIXERFJI0r8IiIiaUSJX0REJI38f+kGNgHUuWR7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Summary of Response \"Credit_Rating\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    8034.000000\n",
       "mean      618.481320\n",
       "std        75.088475\n",
       "min       353.837009\n",
       "25%       594.377473\n",
       "50%       630.049322\n",
       "75%       664.552099\n",
       "max       728.753781\n",
       "Name: Credit_Rating, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.kdeplot(train_final['Credit_Rating'], ax=ax)\n",
    "\n",
    "ax.set_title(\"Distribution of the response 'Credit_Rating'\")\n",
    "ax.set_xlabel('Credit Rating')\n",
    "ax.set_ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "print('Statistical Summary of Response \"Credit_Rating\":')\n",
    "train_final['Credit_Rating'].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8924032e",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Predictor Distribution Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>29.221309</td>\n",
       "      <td>53.129903</td>\n",
       "      <td>-500.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>711.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual_Income</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>39756.415694</td>\n",
       "      <td>25094.001345</td>\n",
       "      <td>8459.020000</td>\n",
       "      <td>20701.211250</td>\n",
       "      <td>34107.420000</td>\n",
       "      <td>56408.135000</td>\n",
       "      <td>781808.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>3282.670144</td>\n",
       "      <td>1752.824797</td>\n",
       "      <td>989.594583</td>\n",
       "      <td>1747.830833</td>\n",
       "      <td>2845.254167</td>\n",
       "      <td>4663.861875</td>\n",
       "      <td>7309.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>5.016928</td>\n",
       "      <td>2.909389</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>5.357605</td>\n",
       "      <td>5.265296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>147.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>2.927931</td>\n",
       "      <td>2.157650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>12.411501</td>\n",
       "      <td>6.087740</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>9.794203</td>\n",
       "      <td>3.569070</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>7.120000</td>\n",
       "      <td>9.480000</td>\n",
       "      <td>12.137500</td>\n",
       "      <td>17.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>5.132686</td>\n",
       "      <td>4.858646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>1110.336964</td>\n",
       "      <td>567.402124</td>\n",
       "      <td>268.830000</td>\n",
       "      <td>656.020000</td>\n",
       "      <td>1053.720000</td>\n",
       "      <td>1406.010000</td>\n",
       "      <td>2576.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>32.242541</td>\n",
       "      <td>2.941859</td>\n",
       "      <td>27.209830</td>\n",
       "      <td>29.652694</td>\n",
       "      <td>32.234927</td>\n",
       "      <td>34.786044</td>\n",
       "      <td>37.414982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>96.537481</td>\n",
       "      <td>333.861590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.064890</td>\n",
       "      <td>54.079318</td>\n",
       "      <td>101.066216</td>\n",
       "      <td>9505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>159.373058</td>\n",
       "      <td>126.226135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.368173</td>\n",
       "      <td>122.439148</td>\n",
       "      <td>203.326017</td>\n",
       "      <td>934.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <td>8034.0</td>\n",
       "      <td>366.782049</td>\n",
       "      <td>132.535989</td>\n",
       "      <td>0.599640</td>\n",
       "      <td>281.369138</td>\n",
       "      <td>343.811565</td>\n",
       "      <td>434.037787</td>\n",
       "      <td>891.209300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count          mean           std          min  \\\n",
       "Age                       8034.0     29.221309     53.129903  -500.000000   \n",
       "Annual_Income             8034.0  39756.415694  25094.001345  8459.020000   \n",
       "Monthly_Inhand_Salary     8034.0   3282.670144   1752.824797   989.594583   \n",
       "Num_Bank_Accounts         8034.0      5.016928      2.909389    -1.000000   \n",
       "Num_Credit_Card           8034.0      5.357605      5.265296     1.000000   \n",
       "Num_of_Loan               8034.0      2.927931      2.157650     0.000000   \n",
       "Num_of_Delayed_Payment    8034.0     12.411501      6.087740    -3.000000   \n",
       "Changed_Credit_Limit      8034.0      9.794203      3.569070     3.630000   \n",
       "Num_Credit_Inquiries      8034.0      5.132686      4.858646     0.000000   \n",
       "Outstanding_Debt          8034.0   1110.336964    567.402124   268.830000   \n",
       "Credit_Utilization_Ratio  8034.0     32.242541      2.941859    27.209830   \n",
       "Total_EMI_per_month       8034.0     96.537481    333.861590     0.000000   \n",
       "Amount_invested_monthly   8034.0    159.373058    126.226135     0.000000   \n",
       "Monthly_Balance           8034.0    366.782049    132.535989     0.599640   \n",
       "\n",
       "                                   25%           50%           75%  \\\n",
       "Age                          24.000000     33.000000     43.000000   \n",
       "Annual_Income             20701.211250  34107.420000  56408.135000   \n",
       "Monthly_Inhand_Salary      1747.830833   2845.254167   4663.861875   \n",
       "Num_Bank_Accounts             3.000000      5.000000      7.000000   \n",
       "Num_Credit_Card               4.000000      5.000000      7.000000   \n",
       "Num_of_Loan                   1.000000      3.000000      4.000000   \n",
       "Num_of_Delayed_Payment        9.000000     12.000000     17.000000   \n",
       "Changed_Credit_Limit          7.120000      9.480000     12.137500   \n",
       "Num_Credit_Inquiries          2.000000      4.000000      7.000000   \n",
       "Outstanding_Debt            656.020000   1053.720000   1406.010000   \n",
       "Credit_Utilization_Ratio     29.652694     32.234927     34.786044   \n",
       "Total_EMI_per_month          24.064890     54.079318    101.066216   \n",
       "Amount_invested_monthly      71.368173    122.439148    203.326017   \n",
       "Monthly_Balance             281.369138    343.811565    434.037787   \n",
       "\n",
       "                                    max  \n",
       "Age                          711.000000  \n",
       "Annual_Income             781808.000000  \n",
       "Monthly_Inhand_Salary       7309.870000  \n",
       "Num_Bank_Accounts            105.000000  \n",
       "Num_Credit_Card              147.000000  \n",
       "Num_of_Loan                   49.000000  \n",
       "Num_of_Delayed_Payment       195.000000  \n",
       "Changed_Credit_Limit          17.190000  \n",
       "Num_Credit_Inquiries         208.000000  \n",
       "Outstanding_Debt            2576.960000  \n",
       "Credit_Utilization_Ratio      37.414982  \n",
       "Total_EMI_per_month         9505.000000  \n",
       "Amount_invested_monthly      934.368000  \n",
       "Monthly_Balance              891.209300  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_stats = train_final.describe().drop(['Unnamed: 0','Credit_Rating','Credit_Mix_Bad','Credit_Mix_Good','Credit_Mix_Standard',\n",
    "                                                 'Payment_of_Min_Amount_No','Payment_of_Min_Amount_Yes'],axis=1)\n",
    "print('Continuous Predictor Distribution Table:')\n",
    "distribution_stats.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1811838",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Predictor Distribution Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit_Mix_Bad</td>\n",
       "      <td>0</td>\n",
       "      <td>7346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit_Mix_Bad</td>\n",
       "      <td>1</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit_Mix_Good</td>\n",
       "      <td>0</td>\n",
       "      <td>5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credit_Mix_Good</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Credit_Mix_Standard</td>\n",
       "      <td>1</td>\n",
       "      <td>4867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Credit_Mix_Standard</td>\n",
       "      <td>0</td>\n",
       "      <td>3167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Payment_of_Min_Amount_No</td>\n",
       "      <td>0</td>\n",
       "      <td>4519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Payment_of_Min_Amount_No</td>\n",
       "      <td>1</td>\n",
       "      <td>3515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Payment_of_Min_Amount_Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>4519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Payment_of_Min_Amount_Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Variable Category Frequency\n",
       "0             Credit_Mix_Bad        0      7346\n",
       "1             Credit_Mix_Bad        1       688\n",
       "2            Credit_Mix_Good        0      5555\n",
       "3            Credit_Mix_Good        1      2479\n",
       "4        Credit_Mix_Standard        1      4867\n",
       "5        Credit_Mix_Standard        0      3167\n",
       "6   Payment_of_Min_Amount_No        0      4519\n",
       "7   Payment_of_Min_Amount_No        1      3515\n",
       "8  Payment_of_Min_Amount_Yes        1      4519\n",
       "9  Payment_of_Min_Amount_Yes        0      3515"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_var = ['Credit_Mix_Bad','Credit_Mix_Good','Credit_Mix_Standard',\n",
    "                            'Payment_of_Min_Amount_No','Payment_of_Min_Amount_Yes']\n",
    "\n",
    "distribution_table = pd.DataFrame(columns=['Variable', 'Category', 'Frequency'])\n",
    "\n",
    "for var in cat_var:\n",
    "    distribution_stats = train_final[var].value_counts(dropna=False)\n",
    "    missing_values = train_final[var].isnull().sum()\n",
    "    temp_df = pd.DataFrame({\n",
    "        'Variable': var,\n",
    "        'Category': distribution_stats.index,\n",
    "        'Frequency': distribution_stats.values,\n",
    "    })\n",
    "\n",
    "    distribution_table = distribution_table.append(temp_df, ignore_index=True)\n",
    "\n",
    "print(\"Categorical Predictor Distribution Table:\")\n",
    "distribution_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb11c9b",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f12d5d",
   "metadata": {},
   "source": [
    "I visualized the distribution of all predictors, continuous and categorical. I noticed many many outliers and extreme values for the continuous predictors from the visualizations. We dropped as many of the outliers as we could, dropping our data from 100,000 rows to around 8,000 rows. However, this was very helpful with our RMSE as our base model RMSE dropped from 209.98 to 86.83 without the outliers. An example visualization of our \"Age\" predictor is provided below, in which you can see the dataset included people of age -500 years and up to 8000 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a59729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Age', ylabel='Density'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(train_final.Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c782c",
   "metadata": {},
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03379eb",
   "metadata": {},
   "source": [
    "I decided to use MARS and Bagged MARS, Bagged Trees, Random Forest, and XGBoost. I anticipated extraordinarily long run times with grid searching, some taking hours to complete. Upon first creating the models, I ran into some problems with models computing particular observations within the dataset, which led to the discovery of just how dirty the dataset was and the solutions found in the data preparation section of this report. Otherwise, no major problems were encountered.\n",
    "\n",
    "There are already solutions posted on Kaggle; however, these solutions pertained to classification instead of regression. Thus, the solutions and strategies were considerable different from those found online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab331a",
   "metadata": {},
   "source": [
    "## Developing the Model: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea422beb",
   "metadata": {},
   "source": [
    "### MARS and Bagged MARS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531d076",
   "metadata": {},
   "source": [
    "The first steps in creating the MARS model was to run through a 5-fold cross validation to find the optimal degrees for the model. Using maximum_term=1000 and a degree range from 1 to 10, the results yielded an optimum degree of 2 with a test RMSE of **64.582452**. Further investigation of the model showed 19 degrees of freedom, excluding the intercept. Below is the final MARS model:\n",
    "\n",
    "*MARS = Earth(max_terms=1000, max_degree=2, feature_importance_type= 'rss')*\n",
    "\n",
    "This model is able to be improved by using MARS as the base estimator in a bagging model. The following hyperparameters were investigated:\n",
    "\n",
    "`n_estimators`: determines the number of decision trees that will be created in the ensemble. \n",
    "\n",
    "`max_samples`: controls the number or proportion of samples from the training data that will be randomly selected for each tree.\n",
    "\n",
    "`max_features`: determines the number or proportion of features to consider when looking for the best split during the construction of each tree.\n",
    "\n",
    "Searching through the following grid search yielded a test RMSE greater than that of the initial MARS model of **65.18251923571461**:\n",
    "\n",
    "       {'n_estimators': [200, 300, 400],\n",
    "        'max_samples': [1.0, 1.5],\n",
    "        'max_features': [0.25, 0.5, 0.75]}\n",
    "\n",
    "The model needs finer tuning after these initial results. Upon further investigation and testing of parameters using a few random searches, the following grid search yielded the best test RMSE of **61.90342908024614** using a 'max_features' of 0.5, a 'max_samples' of 1.0, and an 'n_estimators' of 200:\n",
    "\n",
    "        {'n_estimators': [100,150,200],\n",
    "         'max_samples': [0.5,1.0],\n",
    "         'max_features': [0.5,1.0],}\n",
    "\n",
    "Below is the final model used in the ensemble model:\n",
    "\n",
    "*model1 = BaggingRegressor(base_estimator=MARS, n_estimators=250, random_state=1,\n",
    "                        oob_score=True,n_jobs=-1,bootstrap_features=True,bootstrap=True,\n",
    "                        max_features=1.0,max_samples=1.0)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fbd0e",
   "metadata": {},
   "source": [
    "### Bagged Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea079b",
   "metadata": {},
   "source": [
    "In my Bagged trees models, the first thing I did was graph the OOB R-squared and R-squred on the train data vs the number of trees, which basically narrowed down my n_estimators to around 150-250. This is where I started in my grid search. The paramaters of my first grid search and the results are below: \n",
    "Paramaters of Coarse Grid:  \n",
    "        \n",
    "        {'n_estimators': [150,200,250],\n",
    "          'max_samples': [0.5,1.0],\n",
    "          'max_features': [0.5,1.0],\n",
    "          'bootstrap': [True, False],\n",
    "          'bootstrap_features': [True, False]}\n",
    "          \n",
    " \n",
    "Optimal parameters of Coarse Grid: \n",
    "\n",
    "        {'bootstrap': True, \n",
    "        'bootstrap_features': False, \n",
    "        'max_features': 0.5, \n",
    "        'max_samples': 1.0, \n",
    "        'n_estimators': 250}\n",
    " \n",
    "Test RMSE Grid Search: **62.63951642827617**\n",
    "\n",
    "\n",
    "From these results, I decided to increase the range of n_estimators from 150-250 to 250-350, the range of the max_features from [.5, 1] to [.4, .5, .6], and I kept bootstrap and boostrap_features the same to encompass both True and False values. \n",
    "\n",
    "\n",
    "Finer Grid Search 1: \n",
    "Parameters of Finer Grid 1: \n",
    "\n",
    "         {'n_estimators': [250, 300, 350],\n",
    "          'max_samples': [1.0],\n",
    "          'max_features': [0.4, 0.5, 0.6],\n",
    "          'bootstrap': [True],\n",
    "          'bootstrap_features': [True, False]}\n",
    " \n",
    "Optimal paramters of Finer Grid 1: \n",
    "\n",
    "\n",
    "        {'bootstrap': True, \n",
    "        'bootstrap_features': True, \n",
    "        'max_features': 0.6,\n",
    "        'max_samples': 1.0, \n",
    "        'n_estimators': 350}\n",
    "Test RMSE Finer Grid 1: **62.3023511506021**\n",
    "\n",
    "From this finer grid search, I was able to decrease the Test RMSE by .3. Thus, for my second finer grid serch I increased the range of n_estimators to [350, 500], and kept the max_features the same. This finer grid search yielded a test RMSE of **62.363417489451514**, which was basically an increase so I realized I was going in the wrong direction. For my third and final grid search, I decided to use the max_features of [0.5, 1], and increase the range of n_estimators to [250, 400] to make sure I was not overlooking any better combination. The third finer grid search is below:\n",
    "\n",
    "Finer Grid Search 3: \n",
    "Parameters of Finer Grid 3: \n",
    "\n",
    "        {'n_estimators': [250, 300, 400],\n",
    "          'max_samples': [1.0],\n",
    "          'max_features': [0.4, 0.5, 0.6, 1.0],\n",
    "          'bootstrap': [True],\n",
    "          'bootstrap_features': [True, False]}\n",
    "\n",
    "Optimal parameters of Finer Grid 3: \n",
    "\n",
    "        {'bootstrap': True, \n",
    "        'bootstrap_features': False, \n",
    "        'max_features': 0.5,\n",
    "        'max_samples': 1.0, \n",
    "        'n_estimators': 400}\n",
    "        \n",
    "This got my final test RMSE to **62.27130373550364**, which is the lowest RMSE of the 4 total grid searches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916849c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2605b75",
   "metadata": {},
   "source": [
    "For Random Forest, the first thing I did was plot the number of tress (n_estimators) against RMSE to see if there was an optimal n_estimators where RMSE seemed to stabilize. The graph showed that 400-500 n_estimators gave the lowest RMSE, and after testing around, I found that around 450 n_estimaros was a good number to fix the hyper parameter to.\n",
    "\n",
    "Using that, I started my course grid search by looking first at, on top of n_estimators, max_depth, max_leaf_nodes, and max_features. The hyperparameter grid was:\n",
    "\n",
    "          {'max_depth': [12,15,18],\n",
    "          'max_leaf_nodes':[1100,1200,1300],\n",
    "          'max_features': list(range(1,20))}\n",
    " \n",
    "and the optimal parameters for the initial course grid were (18, 1100, 3). This initial course grid gave me an RMSE of **61.291055**. \n",
    "\n",
    "What I noticed from this course grid was that the optimal max_depth and max_leaf_nodes were at the top of the range. I moved the range of those two hyperparameters to include higher numbers in the next course grid. I noticed that max_features gave a really low optimal number (3). What I did was then hone into a smaller range for my next grid. The hyperparameter grid of my first finer grid was:\n",
    "\n",
    "          {'max_depth': range(15, 25, 3),\n",
    "          'max_leaf_nodes':range(1300, 1600, 100),\n",
    "          'max_features': list(range(1,5))}\n",
    "          \n",
    "and the optimal parameters for this grid search were (21, 1300, 3). This grid search gave me an RMSE of **61.41167**.  From this grid search, the optimal hyperparameters were returning numbers fairly in the middle of the range that I inputed. However, because I got a slightly higher RMSE than the course grid, I played around a little more with max_leaf_nodes and found that the optimal was always between 1300-1500, so I kept that range the same. Similarly, for max_depth, I ran different ranges and the optimal was always between 20-24. For my last grid search, I played around with other hyperparameters, and I found that only the bootstrap hyperparameter provided further improvement to the model. My last grid search was:\n",
    "\n",
    "          {'max_depth': range(15, 25, 3),\n",
    "          'max_leaf_nodes':range(1300, 1600, 100),\n",
    "          'max_features': list(range(1,5)),\n",
    "          'bootstrap': [True, False]}\n",
    "          \n",
    "The optimal parameters for this search was (24, 1300, 2, False). This gave me the lowest RMSE of **61.1911**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f552ef",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f57ee6",
   "metadata": {},
   "source": [
    "For my XGBoost model, I wanted to tune `max_depth`, `learning_rate`, `reg_lambda`, `n_estimators`, `gamma`, `subsample`, and `colsample_bytree`. I first ran a two-fold course grid search using RandomizedSearchCV where `n_iter = 200` with the following parameters: \n",
    "\n",
    "          {'max_depth': [5,6,7],\n",
    "          'learning_rate': [0.01,0.1],\n",
    "          'reg_lambda':[0,1,10],\n",
    "          'n_estimators':[1000, 2000, 3000],\n",
    "          'gamma': [50,100],\n",
    "          'subsample': [0.5,0.75,1.0],\n",
    "          'colsample_bytree': [0.2,0.4]}\n",
    "\n",
    "From this initial course grid search, I found the optimal hyperparameters to be: \n",
    "\n",
    "          {'subsample': 0.75, \n",
    "          'reg_lambda': 0, \n",
    "          'n_estimators': 1000, \n",
    "          'max_depth': 7, \n",
    "          'learning_rate': 0.01, \n",
    "          'gamma': 100, \n",
    "          'colsample_bytree': 0.2}\n",
    "\n",
    "These hyperparameters gave me a test RMSE of **62.478267689982445**. Before performing a finer grid search, I visualized the 2-fold mean test scores with each of the hyperparameter values considered. I found that increasing `max_depth` and lowering `n_estimators` seemed to lower RMSE. Taking these observations into account for my first finer grid search, I ran a five-fold grid search using RandomizedSearchCV where `n_iters = 200` with the following parameters: \n",
    "\n",
    "           {'max_depth': [6,7,8],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'reg_lambda':[0, 1, 10],\n",
    "           'n_estimators':[100, 500, 1000],\n",
    "           'gamma': [0, 10, 50],\n",
    "           'subsample': [0.5, 0.75, 1.0],\n",
    "           'colsample_bytree': [0.2, 0.4, 0.75]}\n",
    "From this first finer grid search, I found the optimal hyperparameters to be: \n",
    "\n",
    "           {'subsample': 1.0, \n",
    "           'reg_lambda': 1, \n",
    "           'n_estimators': 1000, \n",
    "           'max_depth': 8, \n",
    "           'learning_rate': 0.01, \n",
    "           'gamma': 10, \n",
    "           'colsample_bytree': 0.4}\n",
    "These hyperparameters gave me a test RMSE of **62.36942585234199**. I wanted to see if I could still get the test RMSE lower by using more specific values. I decided to run another five-fold grid search using RandomizedSearchCV where `n_iters = 200` with the following parameters:\n",
    "\n",
    "            {'max_depth': [7,8],\n",
    "            'learning_rate': [0.01,0.0088],\n",
    "            'reg_lambda':[0.4],\n",
    "            'n_estimators':[1000,1650],\n",
    "            'gamma': [10,15],\n",
    "            'subsample': [0.5,0.75],\n",
    "            'colsample_bytree': [0.4]}\n",
    "My final optimal hyperparameters from this grid search were: \n",
    "    \n",
    "            {'subsample': 0.75, \n",
    "            'reg_lambda': 0.4, \n",
    "            'n_estimators': 1000, \n",
    "            'max_depth': 8, \n",
    "            'learning_rate': 0.0088, \n",
    "            'gamma': 15, \n",
    "            'colsample_bytree': 0.4}\n",
    "My final test RMSE was: **62.148381497806774**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2594f1",
   "metadata": {},
   "source": [
    "## Model Ensemble "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e3d51",
   "metadata": {},
   "source": [
    "For model ensembling, I created both voting and stacking ensemble models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5924a",
   "metadata": {},
   "source": [
    "### Voting ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a31cb2",
   "metadata": {},
   "source": [
    "For voting ensemble, I created a model that utilized all four individual models (bagged MARS, bagged trees, random forest, and XGBoost) with equal weights. I achieved an RMSE of **61.593737837648646**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff4cda",
   "metadata": {},
   "source": [
    "### Stacking ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca856140",
   "metadata": {},
   "source": [
    "For stacking ensemble, I also utilized all four of the individual models. I decided to use linear regression as the meta model. I was able to achieve an RMSE of **61.44450740075918**, which is slightly lower than the voting ensemble model. Therefore, I used the stacking ensemble as my final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46343d",
   "metadata": {},
   "source": [
    "## Limitations of the Model with Regard to Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8a813",
   "metadata": {},
   "source": [
    "It is possible that the individual models could be better tuned. If I had more time/resources, I would have ran finer grid searches with very specific values to determine if the models are particularly sensitive to a certain hyperparameter. For XGBoost, I used RandomizedSearchCV instead of GridSearchCV because the code took particularly long to run. Using 5-fold GridSearchCV might yield more precise optimal results. However, since I achieved fairly similar RMSE results from all the models I tuned, it is unlikely that better tuning would result in significantly lower RMSE values. \n",
    "\n",
    "Another limitation of my models is that I had to do a lot of cleaning. Some of the predictor values in the dataset were very unrealistic (for example, some of the values in the `Age` column were in the thousands), so I had to drop these rows. Because of this, the bagging and random forest models did better compared to XGBoost.\n",
    "\n",
    "In the US, credit scores are used to measure the risk of an individual as a borrower. I believe that my model will continue to be useful as long as the current methods of calculating credit scores remain consistent. However, it is imperative to take into account any new trends or patterns that might change the relative importance of the predictors so that I can ensure that the model is continuing to provide useful insights and predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a185cb",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4564f8",
   "metadata": {},
   "source": [
    "Based on the model, I have drawn conclusions that can provide valuable insights and recommendations. \n",
    "\n",
    "For lenders, I recommend ensuring that borrowers understand the important predictors that influence interest rates. This can be achieved by establishing clear and transparent communication channels with borrowers, educating them about the factors that impact interest rates. Lenders should also provide personalized feedback on borrowers' credit scores, highlighting specific areas for improvement to help them secure better rates. Additionally, offering financial literacy programs or resources can empower borrowers to make informed financial decisions and improve their credit.\n",
    "\n",
    "For borrowers, I recommend understanding the predictors that influence credit scores to make better financial decisions. Lenders should provide borrowers with regular access to their credit reports and scores, enabling them to monitor their financial standing and identify areas for improvement. Furthermore, educating borrowers about responsible financial behavior, such as making timely payments, maintaining low credit utilization, and diversifying credit types, is crucial for long-term credit improvement.\n",
    "\n",
    "It is important to be aware of the limitations of the model. Credit scores are not the sole determinant of creditworthiness, and other factors such as income, employment history, and debt-to-income ratio should be considered. Additionally, the accuracy of the model may vary based on the quality and completeness of customer information. Therefore, individuals must ensure the use of reliable and up-to-date data for predictions.\n",
    "\n",
    "Regarding the model's future use, it can be updated periodically using recent data to improve accuracy and relevance. Individuals should establish a process for regular model updates, considering new trends, changing lending practices, and advancements in credit-scoring methodologies. The frequency of updates should be determined based on the availability of fresh data and the rate of change in the lending landscape.\n",
    "\n",
    "My final hope is that this collaborative effort will result in better financial outcomes for individuals, improved risk assessment for lenders, and a more inclusive credit environment overall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
